{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "savunma.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq672y9uNbTb",
        "outputId": "87e9ed39-aad4-4bb7-f175-6b0b47271462"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: foolbox in /usr/local/lib/python3.6/dist-packages (3.3.1)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.6/dist-packages (from foolbox) (2.25.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from foolbox) (53.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.6/dist-packages (from foolbox) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from foolbox) (1.19.5)\n",
            "Requirement already satisfied: eagerpy==0.29.0 in /usr/local/lib/python3.6/dist-packages (from foolbox) (0.29.0)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.6/dist-packages (from foolbox) (3.1.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.24.0->foolbox) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.24.0->foolbox) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.5)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (3.0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd2jW6C2Nmea"
      },
      "source": [
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqsac7FMSyD"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import torchvision.models as models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBnc3FnMcdF"
      },
      "source": [
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 600)\n",
        "        self.fc2 = nn.Linear(600, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.25)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = self.drop_layer(F.relu(self.conv3(x)))\n",
        "        x = self.drop_layer(F.relu(self.conv4(x)))\n",
        "        x = x.view(-1, 7*7*64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdHxJYlYNs43"
      },
      "source": [
        "def unc_defense(image,model,epsilon, num_iter, alpha):\n",
        "\n",
        "    torch.manual_seed(2)\n",
        "    np.random.seed(2)\n",
        "\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    image = image.detach()\n",
        "\n",
        "    delta = torch.zeros_like(image, requires_grad=True)\n",
        "    delta.grad = None\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        o = model(image)\n",
        "        o = softmax(o)\n",
        "    init_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    lbls = torch.squeeze(init_pred,1)\n",
        "\n",
        "    enable_dropout(model)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "\n",
        "        dropout_predictions = torch.zeros([50,item_count,10])\n",
        "\n",
        "        for i in range(50):\n",
        "\n",
        "            enable_dropout(model)\n",
        "            output = model((image+delta).clamp(0,1))\n",
        "            output = softmax(output)\n",
        "\n",
        "            dropout_predictions[i] = output\n",
        "\n",
        "\n",
        "        variance = torch.var(dropout_predictions, dim=0)\n",
        "\n",
        "        var = variance.mean(1,True)\n",
        "        var = var.reshape(1,item_count)\n",
        "        var = var.to(device)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        o = model((image + delta).clamp(0, 1))\n",
        "        loss = nn.CrossEntropyLoss(reduce=False)(o, lbls)\n",
        "        loss = loss.reshape(1, item_count)\n",
        "\n",
        "        if t == 0:\n",
        "\n",
        "            loss.backward(torch.ones_like(var))\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            var.backward(torch.ones_like(var))\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                o = model((image + delta).clamp(0, 1))\n",
        "                o = softmax(o)\n",
        "            inter_pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            inds_notmatch = np.where(inter_pred.cpu() != init_pred.cpu())[0]\n",
        "\n",
        "            temp = torch.ones_like(var)\n",
        "            temp = temp.cpu().numpy()\n",
        "\n",
        "            temp[0][inds_notmatch] = 0\n",
        "            temp = torch.tensor(temp)\n",
        "            temp = temp.to(device)\n",
        "\n",
        "            var.backward(temp)\n",
        "            delta_unc = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            loss.backward(temp)\n",
        "            delta_loss = delta.grad.detach().sign()\n",
        "            delta.grad.zero_()\n",
        "            delta.grad = None\n",
        "\n",
        "            zeros = torch.zeros_like(delta_loss)\n",
        "            delta_unc = torch.where(delta_unc == delta_loss, zeros, delta_unc)\n",
        "            delta.data = (delta - alpha * delta_unc).clamp(-epsilon, epsilon)\n",
        "\n",
        "    # model.eval()\n",
        "    perturbed_image = image + delta.detach()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcCTWpJeMhmH"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "batch_size = 64\n",
        "eps = 0.05\n",
        "alpha = 0.2 * eps\n",
        "num_iter = 10\n",
        "eps_l2 = 0.67\n",
        "\n",
        "eps_little = 0.001\n",
        "alpha_reverse = 0.2 * eps_little\n",
        "num_iter_reverse = 10\n",
        "\n",
        "count_successful_reverse = 0\n",
        "count_unsuccessful_reverse = 0\n",
        "\n",
        "count_successfull_attack = 0\n",
        "count_unsuccessfull_attack = 0\n",
        "\n",
        "test_data = datasets.FashionMNIST(root='/FashionData', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwKm-A1gM1ZC",
        "outputId": "db22112c-fced-4b60-c8c0-1c433c51651d"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_cnn = Model_Drop()\n",
        "model_cnn.load_state_dict(torch.load(\"model_cnn.pt\",map_location=device))\n",
        "model_cnn.eval()\n",
        "model_cnn.to(device)\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "corrects = []\n",
        "corrects_tuple_list = []\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-23 09:44:15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go6C5yBDM5AC"
      },
      "source": [
        "for i, (image, label) in enumerate(test_loader):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(image)\n",
        "        o = softmax(o)\n",
        "\n",
        "    pred_original = o.data.max(1, keepdim=True)[1]\n",
        "    pred_original = pred_original.view_as(label)\n",
        "    inds_correct = np.where(pred_original.cpu() == label.cpu())[0]\n",
        "\n",
        "    image = image[inds_correct]\n",
        "    label = label[inds_correct]\n",
        "\n",
        "\n",
        "    #attack = LinfDeepFoolAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    attack = L2CarliniWagnerAttack(steps=1000, abort_early=False)\n",
        "    fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "    raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps_l2])\n",
        "    pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    #attack = L2DeepFoolAttack()\n",
        "    #fmodel = PyTorchModel(model_cnn, bounds=(0, 1))\n",
        "    #raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[eps_l2])\n",
        "    #pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "    # pert = image\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(pert)\n",
        "        o = softmax(o)\n",
        "    pred_pert = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "\n",
        "    pred_pert = pred_pert.view_as(label)\n",
        "\n",
        "    inds_correct_after_attack = np.where(pred_pert.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_attack = np.where(pred_pert.cpu() != label.cpu())[0]\n",
        "\n",
        "\n",
        "    if inds_wrong_after_attack.shape[0] == 0:\n",
        "        continue\n",
        "\n",
        "    image = image[inds_wrong_after_attack]\n",
        "    label = label[inds_wrong_after_attack]\n",
        "    pert = pert[inds_wrong_after_attack]\n",
        "    pred_pert = pred_pert[inds_wrong_after_attack]\n",
        "\n",
        "    reversed_pert = unc_defense(pert, model_cnn, eps_little, num_iter_reverse, alpha_reverse)\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        o = model_cnn(reversed_pert)\n",
        "        o = softmax(o)\n",
        "    pred_reverse = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    pred_reverse = pred_reverse.view_as(label)\n",
        "\n",
        "    inds_correct_after_reverse = np.where(pred_reverse.cpu() == label.cpu())[0]\n",
        "    inds_wrong_after_reverse = np.where(pred_reverse.cpu() != label.cpu())[0]\n",
        "\n",
        "    reversed_pert = reversed_pert[inds_correct_after_reverse]\n",
        "    image = image[inds_correct_after_reverse]\n",
        "    label = label[inds_correct_after_reverse]\n",
        "    pert = pert[inds_correct_after_reverse]\n",
        "    pred_pert = pred_pert[inds_correct_after_reverse]\n",
        "\n",
        "\n",
        "    inds_correct_after_reverse = inds_correct_after_reverse.tolist()\n",
        "    inds_wrong_after_reverse = inds_wrong_after_reverse.tolist()\n",
        "\n",
        "    count_successful_reverse += len(inds_correct_after_reverse)\n",
        "    count_unsuccessful_reverse += len(inds_wrong_after_reverse)\n",
        "\n",
        "    #if i == 0:\n",
        "        #break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-KlO9zTNWN0",
        "outputId": "01d0310c-15ed-4917-8d40-39808a8b2912"
      },
      "source": [
        "print(\"Number of successful reverse operation is : \", count_successful_reverse)\n",
        "print(\"Number of unsuccessful reverse operation is : \", count_unsuccessful_reverse)\n",
        "\n",
        "reformatted_GMT_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(reformatted_GMT_timestamp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of successful reverse operation is :  8331\n",
            "Number of unsuccessful reverse operation is :  19\n",
            "2021-02-23 11:16:14\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}