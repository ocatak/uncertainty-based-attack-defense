{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "adversarial_train_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDiD6L2cNMVe",
        "outputId": "20cfe139-959c-446c-c749-06d137193fae"
      },
      "source": [
        "!git clone https://github.com/knamdar/data.git\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LroJaylUuYdJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "\n",
        "mnist_train = datasets.MNIST(\"data\", train=True, download=False, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"data\", train=False, download=False, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(mnist_train, batch_size = 64, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size = 64, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pljaI0abupYV"
      },
      "source": [
        "torch.manual_seed(2)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SZCsIh1u2ON"
      },
      "source": [
        "class Model_Drop(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Model_Drop, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(10, 10, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(10, 20, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(20, 20, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*20, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.drop_layer = nn.Dropout(p=0.25)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "        x = self.drop_layer(F.relu(self.conv1(x)))\n",
        "        x = self.drop_layer(F.relu(self.conv2(x)))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, 7*7*20)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model_cnn_robust = Model_Drop()\n",
        "model_cnn_robust = model_cnn_robust.to(device)\n",
        "\n",
        "model_cnn_normal = Model_Drop()\n",
        "model_cnn_normal = model_cnn_normal.to(device)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceM_jADCvKai"
      },
      "source": [
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "\n",
        "def pgd_linf(model, X, y, epsilon=0.1, alpha=0.01, num_iter=20, randomize=False):\n",
        "    model.eval()\n",
        "    if randomize:\n",
        "        delta = torch.rand_like(X, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "    else:\n",
        "        delta = torch.zeros_like(X, requires_grad=True)\n",
        "        \n",
        "    for t in range(num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ETx4u4kvdZU"
      },
      "source": [
        "def epoch(loader, model, opt=None):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "\n",
        "    if opt:\n",
        "      model.train()\n",
        "      enable_dropout(model)\n",
        "    else:\n",
        "      model.eval()\n",
        "\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        yp = model(X)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def epoch_adversarial(loader, model, attack, opt=None, **kwargs):\n",
        "    total_loss, total_err = 0.,0.\n",
        "\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "\n",
        "        delta = attack(model, X, y, **kwargs)\n",
        "\n",
        "        if opt:\n",
        "          model.train()\n",
        "        else:\n",
        "          model.eval()\n",
        "\n",
        "        yp = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)        \n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoj7rzFYvuQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8865370a-f00d-4394-d76a-6c7f8e6c8e25"
      },
      "source": [
        "optt = optim.SGD(model_cnn_robust.parameters(), lr=1e-1)\n",
        "\n",
        "for t in range(10):\n",
        "\n",
        "  test_err, test_loss = 0,0\n",
        "\n",
        "  train_err, train_loss = epoch_adversarial(train_loader, model_cnn_robust, pgd_linf, optt)\n",
        "  #train_err, train_loss = epoch(train_loader, model_cnn_normal, optt)\n",
        "\n",
        "  if t == 4:\n",
        "    for param_group in optt.param_groups:\n",
        "      param_group[\"lr\"] = 1e-2\n",
        "  print(*(\"{:.6f}\".format(i) for i in (train_err, test_err)), sep=\"\\t\")\n",
        "\n",
        "model_cnn_robust.eval()\n",
        "torch.save(model_cnn_robust.state_dict(), \"model_cnn_robust.pt\")\n",
        "\n",
        "#model_cnn_normal.eval()\n",
        "#torch.save(model_cnn_normal.state_dict(), \"model_cnn_normal.pt\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.328300\t0.000000\n",
            "0.052200\t0.000000\n",
            "0.036183\t0.000000\n",
            "0.030233\t0.000000\n",
            "0.025933\t0.000000\n",
            "0.019167\t0.000000\n",
            "0.017317\t0.000000\n",
            "0.016817\t0.000000\n",
            "0.016300\t0.000000\n",
            "0.016183\t0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Vaif5V9JqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecef8fb2-09b8-4ae4-b761-74d33b80d97e"
      },
      "source": [
        "model_cnn_robust.eval()\n",
        "print(epoch(test_loader, model_cnn_robust)[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0065\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}